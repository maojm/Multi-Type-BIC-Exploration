%!TEX root = main.tex

\section{Comparative Statics for Explorability}
\label{sec:statics}

%\newcommand{\pairs}{\mP_\omega}
%\newcommand{\pairsPub}{\pairs^{\term{pub}}}
%\newcommand{\pairsPri}{\pairs^{\term{pri}}}
\newcommand{\pairs}{\AExp_{\omega}}
\newcommand{\pairsPub}{\pairs^{\term{pub}}}
\newcommand{\pairsPri}{\pairs^{\term{pri}}}

\newcommand{\support}{\term{support}}

The eventually-explorable type-action pairs are affected by the model choice and the diversity of types.  All else equal, settings with greater potential exploration have greater total expected reward in both the benchmark and approximation guarantee.  
%
Our first result shows that models with public or reported types can explore (strictly) more actions for each type than models with private types.  Thus more type information (strictly) improves outcomes.
%
Our second result shows that {\bf NSI: add something here.}

\xhdr{Explorability and the model choice.}
Fix an instance of Bayesian exploration. We will show in Section~\ref{sec:reported} that the eventually-explorable set of type-action pairs in a given state of the world is the same for public and reported types. Let $\pairsPub$ be the set of all type-action pairs $\{(\theta,a)|a\in\AExp_{\omega,\theta}\}$ be the eventually-explorable type-action pairs in state $\omega$ with public (equivalently, reported) types.  Similarly, let $\pairsPri$ be the set of all type-action pairs $(\theta,m(\theta))$ that appear in some eventually-explorable menu $m\in \MExp_{\omega}$ in state $\omega$ with private types.
%\footnote{For private types, rewards for all type-action pairs in $\pairsPri$ is an ``upper bound" on the information available to the principal. The principal may know ``less" than that: it does not learn the agent type when the recommended menu maps multiple types to the chosen action.}

It is fairly easy to argue that $\pairsPri \subseteq \pairsPub$. The idea in the proof is that one can simulate any BIC recommendation policy for private types with a BIC recommendation policy for public types; we omit the details. {\bf NSI: might want to include it if there's time.}

\begin{claim}
	Any type-action pair eventually-explorable with private types is also eventually-explorable with public types: $\pairsPri \subseteq \pairsPub$.
\end{claim}


Interestingly, as the following example shows, $\pairsPri$ can in fact be a {\em strict} subset of $\pairsPub$.  

\begin{example}
	\label{exp:simple}
	There are two states, two types and two actions: 
	$\varOmega = \varTheta = \A = \{0,1\}$. 
	States and types are drawn uniformly at random:
	$\Pr[\omega =0] =\Pr[\theta =0] = \tfrac12$. 
	Rewards are defined in the following table:\\
	\begin{table}[H]
		\centering
		\begin{tabular}{|c||c|c|}
			\hline
			&$a=0$&$a=1$\\
			\hline
			\hline
			$\theta = 0$& $u = 3$ & $u =4$\\
			\hline
			$\theta = 1$& $u = 2$ & $u =0$\\
			\hline
		\end{tabular}
		\quad
		\begin{tabular}{|c||c|c|}
			\hline
			&$a=0$&$a=1$\\
			\hline
			\hline
			$\theta = 0$& $u = 2$ & $u =0$\\
			\hline
			$\theta = 1$& $u = 3$ & $u =4$\\
			\hline
		\end{tabular}
		\caption{Rewards $u(\theta,a,\omega)$ when $\omega =0 $ and $\omega = 1$.}
	\end{table}
\end{example}

Action 0 is preferred by both types when there is no information beyond the prior about the state. Thus in the first round, the principal must recommend action $0$ in order for the policy to be BIC.  Hence type-action pairs $\{(0,0),(1,0)\}$ are eventually-explorable in all models.

In the second round, the principal knows the reward of the first-round agent.  When types are public or reported, the reward together with the type is sufficient information for the principal to learn the state.  Moving forward, the principal can now recommend the higher-reward action for each type (either directly or, in the case of reported types, through a menu).  Thus, type-action pair $(0,1)$ is eventually-explorable when $\omega=0$ and, similarly, type-action pair $(1,1)$ is eventually-explorable when $\omega=1$.

For private types, samples from the first-round menu (which, as argued above, must recommend action $0$ for both types) do not convey any information about the state, as they have the same distribution in both states. Therefore, action $1$ is not eventually-explorable, for either type and either state.  Thus:

\begin{claim}
	In Example \ref{exp:simple}, $\pairsPri$ is a strict subset of $\pairsPub$.
\end{claim}

\xhdr{Explorability and diversity of agent types.} {\bf NSI: this section needs editing.}
Let us discuss whether and how the type distribution affects the explorable set. Fix an instance of Bayesian Exploration with type distribution $\DT$. Let us see how the explorable set changes if we change $\DT$ to some other distribution $\DT'$. 

Let $\pairs$ and $\pairs'$ be the corresponding explorable sets, for each state $\omega$. Let $\support(\DT)$ be the support set of distribution $\DT$, \ie the set of all feasible agent types according to $\DT$.

For public types, we show that the explorable set is determined by the support set of $\DT$, and can only increase if the support set increases:

\begin{claim}\label{cl:statics-diversity-public}
Consider Bayesian Exploration with public types. Then:
\begin{OneLiners}
\item[(a)] if $\support(\DT)=\support(\DT')$ then $\pairs=\pairs'$.
\item[(b)] if $\support(\DT)\subset \support(\DT')$ then $\pairs\subseteq \pairs'$.
\end{OneLiners}
\end{claim}

\begin{proof}[Proof Sketch]
We follow the steps of the proof of Lemma \ref{lem:exp_public}. The idea is that the proof carries through even if $\pi$ is a BIC recommendation policy for the less diverse problem instance, \ie an instance with type distribution $\DT'$ such that $\support(\DT')\subset \support(\DT)$. Then for a given state $\omega$, Algorithm \ref{alg:public_main} for the original distribution $\DT$ instance explores all type-action pairs in $\pairs'$.
\end{proof}

The conclusions in Claim~\ref{cl:statics-diversity-public} apply to reported types, too. This is because explorable sets are the same for public and reported types.

For private types, the situation is more complicated. More types can help for some problem instances. For example, if different types have disjoint sets of available actions (more formally: say, disjoint sets of actions with positive rewards) then we are essentially back to the case of reported types, and the conclusions in Claim~\ref{cl:statics-diversity-public} apply. On the other hand, 
we can use Example \ref{exp:simple} to show that more types can hurt explorability when types are private. Recall that in this example, for private types only action 0 can be recommended. Now consider a less diverse instance in which only type 0 appears. After one agent in that type chooses action 0, the state is reviewed to the principal. For example, when the state $\omega = 0$, action $1$ can be recommended to future agents. This shows that,  in this example, explorable set increases when we have fewer types. 