\section{Introduction}

Recommendation systems are ubiquitous in modern online economy, recommending movies (Netflix), products (Amazon), restaurants (Yelp), and so on. A typical recommendation system encourages its users to submit evaluations and/or reviews of their experiences, and aggregates this feedback in order to provide better recommendations to future users. Thus, when a user decides which action to take -- which movie to watch, which restaurant to go to, etc. -- she  consumes information from the previous users (indirectly, via recommendations and other information revealed by the system), and may produce new information (e.g., a review) that may benefit future users. This dual role creates an interesting tension between exploration, exploitation, and users' incentives.

On a very abstract level, users make decisions under uncertainty. A social planner -- a hypothetical entity that controls users for the sake of common good -- would balance ``exploration" and ``exploitation", i.e., trying out insufficiently known alternatives for the sake of acquiring new information and making myopic decisions based on this information. Designing algorithms to trade off these two objectives is a well-researched subject in machine learning and operations research; models without persistent state are known as \emph{multi-armed bandits}.

However, incentives are misaligned. If a given user ``explores", she risks having a potentially suboptimal experience, whereas the upside of exploration -- improved recommendations -- is spread over many users in the future. Absent an adequate mechanism to compensate for the risks of exploration, self-interested users have incentives to lean in favor of exploitation. This may result in outcomes that are very suboptimal. First, it may take much longer to arrive at good recommendations. Second, the recommendations may consistently suffer from selection bias in the data: e.g., ratings of a given movie may mostly come from people who like this type or genre of a movie. Third, in some natural but idealized models (e.g., \cite{Kremer-JPE14,ICexploration-ec15}), there are simple  examples when optimal recommendations are never found because the corresponding actions are never taken.

Thus, we have a problem of \emph{incentivizing exploration}: creating incentives for self-interested users to explore so as to benefit others. While monetary incentives such as discounts are sometimes used for this purpose, they are often prohibitively expensive for the system and/or may result in additional selection bias, as the feedback may come from users that are more sensitive to the said discounts. Likewise, relying on a natural human propensity to explore results in a different type of selection bias, when the data reflects users that are more adventurous. 

A recent line of work, started by \cite{Kremer-JPE14}, strives to remove these biases and incentivize exploration by means of controlling the information revealed to the agents. The idea is to take advantage of \emph{information asymmetry}: the fact that the recommendation system has more information than a typical user. These papers posit a simple model, termed \emph{Bayesian Exploration} in \cite{ICexplorationGames-ec16}, in which the recommendation system is a ``principal" that interacts with a stream of self-interested agents. A single round of this model is a well-known ``Bayesian Persuasion game" \cite{Kamenica-aer11}.

We depart from prior work on Bayesian Exploration in that we allow heterogeneous users, more precisely, we do not assume that users have the same preferences from one time step to another. Each user has a ``type" that may be revealed or not revealed to the principal (``public types" vs. ``private types"), depending on the modeling choice. The goal is more ambitious than before: rather than learn one recommendation that is good for everyone on average, we strive to learn the best \emph{personalized} recommendations. 

\ascomment{stopped here.}

\subsection{Ideas and Techniques}
\begin{itemize}
\item Global phase+local phase.
\item Reduce from private type, communication allowed to public types.
\item Information theory.
\end{itemize}

